# Lip Reading (LipNet)
 
This repository contains the implementation of LipNet, a neural network  to accurately transcribe and interpret spoken words solely based on the visual cues provided by the speaker's lips. It operates by taking a sequence of video frames containing the speaker's face as input and produces a corresponding sequence of phonemes or words as output.

Training LipNet involves using a large dataset of paired videos and transcriptions, enabling the model to learn the correlation between visual features and linguistic content. By optimizing its parameters through backpropagation and gradient descent, LipNet can improve its accuracy in lip reading and transcribing spoken words. <br>
Dataset link: [Download](https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL)

LipNet is a proposed by researchers at the University of Oxford in the year 2016. <br>
Original Paper: [Read Now!](https://arxiv.org/abs/1611.01599)

## Streamlit App

![image](https://github.com/HirparaAmit/LipReading-using-DeepLearning/assets/57864056/b61169c4-64a0-4228-8e80-a411a355e936)
